# -*- coding: utf-8 -*-
"""272Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bQIG7oYOJ7AmcoZ4BIKzzgjHy9Urg-cI
"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
import os
import sys

from keras.preprocessing.image import img_to_array, load_img

train_dir = r'/content/drive/My Drive/272 project/food-recognition-challenge/train/train/images'
val_dir = r'/content/drive/My Drive/272 project/food-recognition-challenge/val/val/images'
weights_dir = r'content/drive/My Drive/272 project/food-recognition-challenge/weights'
number_of_output_classes = 2
weights_name = r'food_shazam.h5'  # include extension .h5 in the filename
fine_tune = False
epochs = 2

def train_data_generator(batch_size=16):
  train_datagen = ImageDataGenerator(
                  rescale=1./255,
                  shear_range=0.2,
                  zoom_range=0.2,
                  horizontal_flip=True)

  train_generator = train_datagen.flow_from_directory(
                  train_dir,  # this is the target directory
                  target_size=(150, 150),  # all images will be resized to 150x150
                  batch_size=batch_size,
                  class_mode='categorical',
                  shuffle=True)  # since we use binary_crossentropy loss, we need binary labels

  print(train_generator.class_indices)

  return train_generator


def val_data_generator(batch_size=16):
  val_datagen = ImageDataGenerator(rescale=1./255)

  val_generator = val_datagen.flow_from_directory(
                  val_dir,
                  target_size=(150, 150),
                  batch_size=batch_size,
                  class_mode='categorical',
                  shuffle=True)

  print(val_generator.class_indices)

  return val_generator

def small_convnet():
    model = Sequential()
    model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(32, (3, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(64, (3, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors
    model.add(Dense(64))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(number_of_output_classes))
    model.add(Activation('softmax'))

    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['acc'])

    return model

def train():
  batch_size = 16
  train_generator = train_data_generator(batch_size)
  val_generator = val_data_generator(batch_size)

  model = small_convnet()

  model.summary()

  weights_path = os.path.join(weights_dir, weights_name)

  if fine_tune:
      model.load_weights(weights_path)

  model.fit_generator(
      train_generator,
      steps_per_epoch=2000 // batch_size,
      epochs=epochs,
      validation_data=val_generator,
      validation_steps=800 // batch_size)

  model.save_weights(weights_path)


if __name__ == '__main__':
    train()

from skimage.transform import resize

def predict(img_file):
    img = load_img(img_file)
    return predict_img(img)


def predict_img(img):
    x = img_to_array(img)
    x = resize(x, (150, 150, 3))
    x = x.reshape((1,) + x.shape)

    convnet = small_convnet()

    weights_path = os.path.join(config.weights_dir, config.weights_name)

    convnet.load_weights(weights_path)
    p = convnet.predict_classes(x, verbose=1)
    print(p)
    # get label indices
    train_generator = train_data_generator()
    class_dictionary = train_generator.class_indices
    return list(class_dictionary.keys())[list(class_dictionary.values())[int(p[0])]]


if __name__ == '__main__':
    print("Predicted class is: %s" % (predict("007509.jpg")))

